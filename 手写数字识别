import torch
from torch import nn
import torch.optim as optim
import torchvision
import torchvision.transforms as t
from torch.utils.data import DataLoader

# 定义超参数
batch_size = 100#每次迭代的数据样本为100个
learning_rate = 0.001#学习率精确到0.001
num_epochs = 2#测试的次数

# 数据预处理
f = t.Compose([t.ToTensor(), t.Normalize((0.5,), (0.5,))])#将图像转化为FloatTenser并标准化

# 加载MNIST数据集
train_dataset = torchvision.datasets.MNIST(root='./data',train=True,transform=f,download=False)
test_dataset = torchvision.datasets.MNIST(root='./data',train=False,transform=f,download=False)

#利用pytorch加载数据集
train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)

# 定义神经网络模型
class Network(nn.Module):
    def __init__(self):
        super(Network, self).__init__()
        self.lin1 = nn.Linear(28*28, 100)#线性模型
        self.lin2 = nn.Linear(100, 10)

    def forward(self, x):
        x = x.view(-1, 28*28)
        x = torch.relu(self.lin1(x))
        x = self.lin2(x)
        return x


model = Network()

# 定义损失函数和优化器
criterion = nn.CrossEntropyLoss()#定义损失函数
optimizer = optim.Adam(model.parameters(), lr=learning_rate)#定义优化器这里选用Adam函数进行

# 训练模型
for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(train_loader):
        outputs = model(images)#向前传播
        loss = criterion(outputs, labels)#计算损失

        optimizer.zero_grad()#清除梯度
        loss.backward()#反向传播
        optimizer.step()#更新参数
#如果训练的次数超过100次，则输出训练的损失率
        if (i + 1) % 100 == 0:
            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}')
 # 测试模型
with torch.no_grad():
    correct = 0#记录正确率
    total = 0#总样本数
    for images, labels in test_loader:
        outputs = model(images)#测试模型
        _, predicted = torch.max(outputs.data, 1)#指定索引及最大值并略最大值
        total += labels.size(0)#获取当前样本批次的数目
        correct += (predicted == labels).sum().item()#计算正确率并将其转化为python标量

    print(f'Accuracy of the model on the test images: {100 * correct / total:.2f}%')
